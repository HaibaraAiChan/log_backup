[2021-06-10 06:36:49,245] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2021-06-10 06:36:52,913] [INFO] [runner.py:360:main] cmd = /usr/bin/python3.6 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train_serial.py --batch-size 196615 --deepspeed_config ds_config.json
[2021-06-10 06:36:53,814] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}
[2021-06-10 06:36:53,814] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0
[2021-06-10 06:36:53,814] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2021-06-10 06:36:53,814] [INFO] [launch.py:102:main] dist_world_size=1
[2021-06-10 06:36:53,814] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0
main start at this time 1623307019.5134416
before load_ogb step Time(s): 0.0018
-------------------------------------------------------------from ogb.nodeproppred import DglNodePropPredDataset***************************  
{'VmPeak': 20521.17578125, 'VmSize': 20395.0, 'VmHWM': 1165.09375, 'VmRSS': 1165.09375}  

load ogbn-products
-------------------------------------------------------------data = DglNodePropPredDataset(name=name)*************************** step Time(s): 1.6673
finish loading ogbn-products
-------------------------------------------------------------splitted_idx = data.get_idx_split()*************************** step Time(s): 0.2831
-------------------------------------------------------------graph, labels = data[0]*************************** step Time(s): 0.0000
tensor([[0],
        [1],
        [2],
        ...,
        [8],
        [2],
        [4]])
(Graph(num_nodes=2449029, num_edges=123718280,
      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32)}
      edata_schemes={}), tensor([[0],
        [1],
        [2],
        ...,
        [8],
        [2],
        [4]]))
Graph(num_nodes=2449029, num_edges=123718280,
      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32)}
      edata_schemes={})
-------------------------------------------------------------labels = labels[:, 0]*************************** step Time(s): 0.0012
-------------------------------------------------------------graph.ndata['features'] = graph.ndata['feat']*************************** step Time(s): 0.0002
-------------------------------------------------graph.ndata['labels'] = labels****************** step Time(s): 0.0000
-------------------------------------------------train_nid, val_nid, test_nid = splitted_idx****************** step Time(s): 0.0951
-------------------------------------------------end of load ogb****************** step Time(s): 0.0023
finish constructing ogbn-products
load ogb-products time total: 2.0492799282073975
#nodes: 2449029
#edges: 123718280
#classes: 47
after load_ogb step Time(s): 2.0502
after inductive else step Time(s): 0.0000
after label step Time(s): 3.8094
after train_g.create_formats_() step Time(s): 1.7718
in_feats 100
train_labels.shape torch.Size([2449029])
args.batch_size 196615
SAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_self): Linear(in_features=100, out_features=16, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=16, bias=False)
    )
    (1): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_self): Linear(in_features=16, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=16, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
[2021-06-10 06:37:07,175] [INFO] [logging.py:60:log_dist] [Rank -1] DeepSpeed info: version=0.3.17+unknown, git-hash=unknown, git-branch=unknown
[2021-06-10 06:37:07,176] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl
[2021-06-10 06:37:07,181] [INFO] [utils.py:13:_initialize_parameter_parallel_groups] data_parallel_size: 1, parameter_parallel_size: 1
[2021-06-10 06:37:09,559] [INFO] [engine.py:165:__init__] DeepSpeed Flops Profiler Enabled: False
[2021-06-10 06:37:09,561] [INFO] [engine.py:622:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer
[2021-06-10 06:37:09,561] [INFO] [engine.py:626:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam
[2021-06-10 06:37:09,561] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2021-06-10 06:37:09,561] [INFO] [engine.py:450:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR
[2021-06-10 06:37:09,561] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f0a1ffdc860>
[2021-06-10 06:37:09,561] [INFO] [logging.py:60:log_dist] [Rank 0] step=0, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:37:09,562] [INFO] [config.py:748:print] DeepSpeedEngine configuration:
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   allreduce_always_fp32 ........ False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   amp_enabled .................. False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   amp_params ................... False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   checkpoint_tag_validation_enabled  True
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   checkpoint_tag_validation_fail  False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   disable_allgather ............ False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   dump_state ................... False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   dynamic_loss_scale_args ...... None
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   elasticity_enabled ........... False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   fp16_enabled ................. False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   global_rank .................. 0
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   gradient_accumulation_steps .. 1
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   gradient_clipping ............ 0.0
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   gradient_predivide_factor .... 1.0
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   initial_dynamic_scale ........ 4294967296
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   loss_scale ................... 0
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   memory_breakdown ............. False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   optimizer_legacy_fusion ...... False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   optimizer_name ............... adam
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   optimizer_params ............. {'lr': 0.03, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   pld_enabled .................. False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   pld_params ................... False
[2021-06-10 06:37:09,562] [INFO] [config.py:752:print]   prescale_gradients ........... False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   scheduler_name ............... WarmupLR
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.03, 'warmup_num_steps': 10}
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   sparse_attention ............. None
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   sparse_gradients_enabled ..... False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   steps_per_print .............. 10
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   tensorboard_enabled .......... False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   tensorboard_job_name ......... DeepSpeedJobName
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   tensorboard_output_path ...... 
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   train_batch_size ............. 1500
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   train_micro_batch_size_per_gpu  1500
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   wall_clock_breakdown ......... False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   world_size ................... 1
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   zero_allow_untested_optimizer  False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   zero_config .................. {
    "stage": 0, 
    "contiguous_gradients": false, 
    "reduce_scatter": false, 
    "reduce_bucket_size": 5.000000e+08, 
    "allgather_partitions": true, 
    "allgather_bucket_size": 5.000000e+08, 
    "overlap_comm": false, 
    "load_from_fp32_weights": true, 
    "elastic_checkpoint": true, 
    "offload_param": null, 
    "offload_optimizer": null, 
    "sub_group_size": 1.000000e+12, 
    "prefetch_bucket_size": 5.000000e+07, 
    "param_persistence_threshold": 1.000000e+05, 
    "max_live_parameters": 1.000000e+09, 
    "max_reuse_distance": 1.000000e+09, 
    "gather_fp16_weights_on_model_save": false, 
    "ignore_unused_parameters": true
}
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   zero_enabled ................. False
[2021-06-10 06:37:09,563] [INFO] [config.py:752:print]   zero_optimization_stage ...... 0
[2021-06-10 06:37:09,565] [INFO] [config.py:760:print]   json = {
    "train_batch_size": 1.500000e+03, 
    "steps_per_print": 10, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.03, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "scheduler": {
        "type": "WarmupLR", 
        "params": {
            "warmup_min_lr": 0, 
            "warmup_max_lr": 0.03, 
            "warmup_num_steps": 10
        }
    }, 
    "wall_clock_breakdown": false
}
******************************0 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 2.31494140625GB

Max Memory Allocated 0.9306011199951172  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 3.01220703125GB

Max Memory Allocated 1.6259841918945312  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 3.17431640625GB

Max Memory Allocated 1.6259841918945312  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 4.01806640625GB

Max Memory Allocated 2.007756233215332  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 4.01806640625GB

Max Memory Allocated 2.007756233215332  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 4.52392578125GB

Max Memory Allocated 2.070261001586914  GigaBytes

Epoch 00000 | Step 00000 | Loss 5.6068 | Train Acc 0.0193 | Speed (samples/sec) nan | GPU 2119.9 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 4.52392578125GB

Max Memory Allocated 2.070261001586914  GigaBytes

Epoch Time(s): 7.3850
******************************1 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 4.52392578125GB

Max Memory Allocated 2.070261001586914  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 5.33447265625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 5.46923828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.06298828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch 00001 | Step 00000 | Loss 4.2056 | Train Acc 0.0813 | Speed (samples/sec) nan | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch Time(s): 6.7594
******************************2 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 5.33447265625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 5.46923828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.06298828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch 00002 | Step 00000 | Loss 4.2064 | Train Acc 0.0798 | Speed (samples/sec) nan | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch Time(s): 8.0176
******************************3 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 5.33447265625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 5.46923828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.06298828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch 00003 | Step 00000 | Loss 3.8924 | Train Acc 0.1118 | Speed (samples/sec) 31657.2043 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch Time(s): 6.5028
******************************4 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 5.33447265625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 5.46923828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.06298828125GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch 00004 | Step 00000 | Loss 3.4808 | Train Acc 0.1759 | Speed (samples/sec) 30933.7425 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

Epoch Time(s): 6.8155
******************************5 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.20556640625GB

Max Memory Allocated 2.34470272064209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00005 | Step 00000 | Loss 3.0557 | Train Acc 0.2613 | Speed (samples/sec) 31053.4811 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6282
******************************6 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00006 | Step 00000 | Loss 2.6412 | Train Acc 0.3530 | Speed (samples/sec) 31007.5113 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6809
******************************7 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00007 | Step 00000 | Loss 2.2886 | Train Acc 0.4234 | Speed (samples/sec) 31048.5666 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6099
******************************8 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00008 | Step 00000 | Loss 2.0254 | Train Acc 0.4711 | Speed (samples/sec) 30852.6546 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9236
******************************9 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00009 | Step 00000 | Loss 1.8069 | Train Acc 0.5124 | Speed (samples/sec) 30764.1119 | GPU 2401.0 MB
[2021-06-10 06:38:18,702] [INFO] [logging.py:60:log_dist] [Rank 0] step=10, skipped=0, lr=[0.029999999999999995], mom=[[0.8, 0.999]]
[2021-06-10 06:38:18,702] [INFO] [timer.py:160:stop] 0/10, SamplesPerSec=4010.1227385636166
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8138
******************************10 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00010 | Step 00000 | Loss 1.6433 | Train Acc 0.5474 | Speed (samples/sec) 30637.7792 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9534
******************************11 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00011 | Step 00000 | Loss 1.5060 | Train Acc 0.5831 | Speed (samples/sec) 30704.8054 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.5734
******************************12 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00012 | Step 00000 | Loss 1.3933 | Train Acc 0.6175 | Speed (samples/sec) 30513.1272 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.1730
******************************13 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00013 | Step 00000 | Loss 1.2948 | Train Acc 0.6516 | Speed (samples/sec) 30598.3028 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.5322
******************************14 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00014 | Step 00000 | Loss 1.2197 | Train Acc 0.6822 | Speed (samples/sec) 30519.4145 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9392
******************************15 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00015 | Step 00000 | Loss 1.1554 | Train Acc 0.7053 | Speed (samples/sec) 30523.3847 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.7457
******************************16 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00016 | Step 00000 | Loss 1.0974 | Train Acc 0.7242 | Speed (samples/sec) 30433.2016 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.0093
******************************17 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00017 | Step 00000 | Loss 1.0469 | Train Acc 0.7377 | Speed (samples/sec) 30343.1304 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.1056
******************************18 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00018 | Step 00000 | Loss 1.0036 | Train Acc 0.7523 | Speed (samples/sec) 30406.2623 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6303
******************************19 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00019 | Step 00000 | Loss 0.9639 | Train Acc 0.7645 | Speed (samples/sec) 30394.0329 | GPU 2401.0 MB
[2021-06-10 06:39:27,208] [INFO] [logging.py:60:log_dist] [Rank 0] step=20, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:39:27,209] [INFO] [timer.py:160:stop] 0/20, SamplesPerSec=3969.6749444200605
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8435
******************************20 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00020 | Step 00000 | Loss 0.9278 | Train Acc 0.7739 | Speed (samples/sec) 30280.9403 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.2370
******************************21 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00021 | Step 00000 | Loss 0.8926 | Train Acc 0.7824 | Speed (samples/sec) 30244.5481 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9584
******************************22 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00022 | Step 00000 | Loss 0.8648 | Train Acc 0.7884 | Speed (samples/sec) 30192.2990 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.0501
******************************23 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00023 | Step 00000 | Loss 0.8384 | Train Acc 0.7943 | Speed (samples/sec) 30162.7407 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9631
******************************24 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00024 | Step 00000 | Loss 0.8119 | Train Acc 0.8008 | Speed (samples/sec) 30070.1451 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.3049
******************************25 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00025 | Step 00000 | Loss 0.7917 | Train Acc 0.8058 | Speed (samples/sec) 30034.5754 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.0257
******************************26 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00026 | Step 00000 | Loss 0.7727 | Train Acc 0.8098 | Speed (samples/sec) 30014.0036 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9609
******************************27 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00027 | Step 00000 | Loss 0.7532 | Train Acc 0.8146 | Speed (samples/sec) 30013.2719 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8626
******************************28 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00028 | Step 00000 | Loss 0.7422 | Train Acc 0.8163 | Speed (samples/sec) 29957.5544 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.1912
******************************29 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00029 | Step 00000 | Loss 0.7270 | Train Acc 0.8205 | Speed (samples/sec) 29949.3989 | GPU 2401.0 MB
[2021-06-10 06:40:37,708] [INFO] [logging.py:60:log_dist] [Rank 0] step=30, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:40:37,709] [INFO] [timer.py:160:stop] 0/30, SamplesPerSec=3986.71228432956
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9456
******************************30 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00030 | Step 00000 | Loss 0.7146 | Train Acc 0.8226 | Speed (samples/sec) 29936.9340 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9116
******************************31 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00031 | Step 00000 | Loss 0.7034 | Train Acc 0.8234 | Speed (samples/sec) 29948.6235 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.7941
******************************32 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00032 | Step 00000 | Loss 0.6897 | Train Acc 0.8278 | Speed (samples/sec) 29922.4941 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.0380
******************************33 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00033 | Step 00000 | Loss 0.6777 | Train Acc 0.8296 | Speed (samples/sec) 29922.8763 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8683
******************************34 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00034 | Step 00000 | Loss 0.6708 | Train Acc 0.8309 | Speed (samples/sec) 29924.9830 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8684
******************************35 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00035 | Step 00000 | Loss 0.6617 | Train Acc 0.8335 | Speed (samples/sec) 29918.6282 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9190
******************************36 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00036 | Step 00000 | Loss 0.6546 | Train Acc 0.8361 | Speed (samples/sec) 29869.6680 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.2707
******************************37 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00037 | Step 00000 | Loss 0.6511 | Train Acc 0.8355 | Speed (samples/sec) 29767.2720 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.8224
******************************38 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00038 | Step 00000 | Loss 0.6427 | Train Acc 0.8383 | Speed (samples/sec) 29732.7506 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.2263
******************************39 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00039 | Step 00000 | Loss 0.6339 | Train Acc 0.8399 | Speed (samples/sec) 29702.7039 | GPU 2401.0 MB
[2021-06-10 06:41:48,604] [INFO] [logging.py:60:log_dist] [Rank 0] step=40, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:41:48,604] [INFO] [timer.py:160:stop] 0/40, SamplesPerSec=4008.9046776923874
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.1757
******************************40 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00040 | Step 00000 | Loss 0.6302 | Train Acc 0.8413 | Speed (samples/sec) 29666.2829 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.2115
******************************41 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00041 | Step 00000 | Loss 0.6276 | Train Acc 0.8412 | Speed (samples/sec) 29583.1480 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.7112
******************************42 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00042 | Step 00000 | Loss 0.6207 | Train Acc 0.8427 | Speed (samples/sec) 29594.4511 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8288
******************************43 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00043 | Step 00000 | Loss 0.6146 | Train Acc 0.8437 | Speed (samples/sec) 29573.2928 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 7.1545
******************************44 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00044 | Step 00000 | Loss 0.6121 | Train Acc 0.8435 | Speed (samples/sec) 29580.1089 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8946
******************************45 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00045 | Step 00000 | Loss 0.6107 | Train Acc 0.8434 | Speed (samples/sec) 29590.5711 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.8461
******************************46 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00046 | Step 00000 | Loss 0.6022 | Train Acc 0.8453 | Speed (samples/sec) 29591.3865 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.9798
******************************47 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00047 | Step 00000 | Loss 0.6013 | Train Acc 0.8463 | Speed (samples/sec) 29615.9724 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6708
******************************48 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00048 | Step 00000 | Loss 0.5959 | Train Acc 0.8482 | Speed (samples/sec) 29630.3929 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.7700
******************************49 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00049 | Step 00000 | Loss 0.5960 | Train Acc 0.8484 | Speed (samples/sec) 29656.6869 | GPU 2401.0 MB
[2021-06-10 06:42:58,317] [INFO] [logging.py:60:log_dist] [Rank 0] step=50, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:42:58,318] [INFO] [timer.py:160:stop] 0/50, SamplesPerSec=4055.868640896838
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.6456
******************************50 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 6.01806640625GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 6.15283203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 5.74658203125GB

Max Memory Allocated 2.344742774963379  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch 00050 | Step 00000 | Loss 0.5866 | Train Acc 0.8496 | Speed (samples/sec) 29672.8521 | GPU 2401.0 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 5.88916015625GB

Max Memory Allocated 2.344742774963379  GigaBytes

Epoch Time(s): 6.7468
Eval Acc 0.8579
Test Acc: 0.6821
******************************51 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00051 | Step 00000 | Loss 0.5847 | Train Acc 0.8494 | Speed (samples/sec) 29651.8468 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.2382
******************************52 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00052 | Step 00000 | Loss 0.5863 | Train Acc 0.8496 | Speed (samples/sec) 29658.6798 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8561
******************************53 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00053 | Step 00000 | Loss 0.5804 | Train Acc 0.8495 | Speed (samples/sec) 29661.7461 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9030
******************************54 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00054 | Step 00000 | Loss 0.5776 | Train Acc 0.8506 | Speed (samples/sec) 29666.1593 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8832
******************************55 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00055 | Step 00000 | Loss 0.5755 | Train Acc 0.8525 | Speed (samples/sec) 29674.8606 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8195
******************************56 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00056 | Step 00000 | Loss 0.5714 | Train Acc 0.8529 | Speed (samples/sec) 29703.8582 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.6355
******************************57 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00057 | Step 00000 | Loss 0.5717 | Train Acc 0.8515 | Speed (samples/sec) 29726.4238 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.6689
******************************58 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00058 | Step 00000 | Loss 0.5678 | Train Acc 0.8528 | Speed (samples/sec) 29762.2155 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.4898
******************************59 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00059 | Step 00000 | Loss 0.5617 | Train Acc 0.8546 | Speed (samples/sec) 29765.7674 | GPU 3263.7 MB
[2021-06-10 06:44:32,354] [INFO] [logging.py:60:log_dist] [Rank 0] step=60, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:44:32,354] [INFO] [timer.py:160:stop] 0/60, SamplesPerSec=4042.823224263894
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8759
******************************60 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00060 | Step 00000 | Loss 0.5641 | Train Acc 0.8540 | Speed (samples/sec) 29764.8883 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9204
******************************61 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00061 | Step 00000 | Loss 0.5624 | Train Acc 0.8540 | Speed (samples/sec) 29772.3092 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7973
******************************62 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00062 | Step 00000 | Loss 0.5600 | Train Acc 0.8551 | Speed (samples/sec) 29799.7904 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.5910
******************************63 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00063 | Step 00000 | Loss 0.5591 | Train Acc 0.8554 | Speed (samples/sec) 29799.6808 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9100
******************************64 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00064 | Step 00000 | Loss 0.5596 | Train Acc 0.8550 | Speed (samples/sec) 29776.7736 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.2470
******************************65 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00065 | Step 00000 | Loss 0.5554 | Train Acc 0.8560 | Speed (samples/sec) 29771.6919 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9684
******************************66 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00066 | Step 00000 | Loss 0.5548 | Train Acc 0.8556 | Speed (samples/sec) 29774.5419 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8809
******************************67 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00067 | Step 00000 | Loss 0.5500 | Train Acc 0.8577 | Speed (samples/sec) 29751.9473 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.2572
******************************68 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00068 | Step 00000 | Loss 0.5506 | Train Acc 0.8569 | Speed (samples/sec) 29753.6379 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8911
******************************69 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00069 | Step 00000 | Loss 0.5494 | Train Acc 0.8564 | Speed (samples/sec) 29749.8689 | GPU 3263.7 MB
[2021-06-10 06:45:41,798] [INFO] [logging.py:60:log_dist] [Rank 0] step=70, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:45:41,799] [INFO] [timer.py:160:stop] 0/70, SamplesPerSec=4038.8045982966573
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9801
******************************70 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00070 | Step 00000 | Loss 0.5493 | Train Acc 0.8568 | Speed (samples/sec) 29741.3412 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.0686
******************************71 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00071 | Step 00000 | Loss 0.5482 | Train Acc 0.8576 | Speed (samples/sec) 29749.7861 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8219
******************************72 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00072 | Step 00000 | Loss 0.5463 | Train Acc 0.8571 | Speed (samples/sec) 29765.4619 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.6928
******************************73 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00073 | Step 00000 | Loss 0.5451 | Train Acc 0.8578 | Speed (samples/sec) 29772.5752 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7766
******************************74 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00074 | Step 00000 | Loss 0.5429 | Train Acc 0.8588 | Speed (samples/sec) 29767.8599 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9615
******************************75 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00075 | Step 00000 | Loss 0.5441 | Train Acc 0.8581 | Speed (samples/sec) 29775.9034 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7533
******************************76 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00076 | Step 00000 | Loss 0.5395 | Train Acc 0.8589 | Speed (samples/sec) 29769.1634 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.0234
******************************77 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00077 | Step 00000 | Loss 0.5376 | Train Acc 0.8601 | Speed (samples/sec) 29778.0474 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7422
******************************78 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00078 | Step 00000 | Loss 0.5372 | Train Acc 0.8595 | Speed (samples/sec) 29799.6457 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.5381
******************************79 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00079 | Step 00000 | Loss 0.5361 | Train Acc 0.8599 | Speed (samples/sec) 29749.3976 | GPU 3263.7 MB
[2021-06-10 06:46:51,058] [INFO] [logging.py:60:log_dist] [Rank 0] step=80, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:46:51,058] [INFO] [timer.py:160:stop] 0/80, SamplesPerSec=4053.3874651103783
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.8805
******************************80 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00080 | Step 00000 | Loss 0.5339 | Train Acc 0.8604 | Speed (samples/sec) 29747.7247 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9632
******************************81 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00081 | Step 00000 | Loss 0.5332 | Train Acc 0.8599 | Speed (samples/sec) 29713.9805 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.6085
******************************82 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00082 | Step 00000 | Loss 0.5351 | Train Acc 0.8592 | Speed (samples/sec) 29743.2551 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.4449
******************************83 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00083 | Step 00000 | Loss 0.5314 | Train Acc 0.8611 | Speed (samples/sec) 29755.1932 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.6808
******************************84 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00084 | Step 00000 | Loss 0.5294 | Train Acc 0.8610 | Speed (samples/sec) 29768.2002 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.6801
******************************85 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00085 | Step 00000 | Loss 0.5319 | Train Acc 0.8597 | Speed (samples/sec) 29759.1205 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.1213
******************************86 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00086 | Step 00000 | Loss 0.5271 | Train Acc 0.8614 | Speed (samples/sec) 29760.8637 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8704
******************************87 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00087 | Step 00000 | Loss 0.5310 | Train Acc 0.8602 | Speed (samples/sec) 29754.9719 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.0148
******************************88 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00088 | Step 00000 | Loss 0.5279 | Train Acc 0.8614 | Speed (samples/sec) 29753.9795 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.9347
******************************89 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00089 | Step 00000 | Loss 0.5287 | Train Acc 0.8611 | Speed (samples/sec) 29736.5421 | GPU 3263.7 MB
[2021-06-10 06:48:00,654] [INFO] [logging.py:60:log_dist] [Rank 0] step=90, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:48:00,654] [INFO] [timer.py:160:stop] 0/90, SamplesPerSec=4048.700581005306
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.2765
******************************90 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00090 | Step 00000 | Loss 0.5255 | Train Acc 0.8615 | Speed (samples/sec) 29729.6699 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.0536
******************************91 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00091 | Step 00000 | Loss 0.5246 | Train Acc 0.8624 | Speed (samples/sec) 29688.6749 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.8324
******************************92 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00092 | Step 00000 | Loss 0.5248 | Train Acc 0.8623 | Speed (samples/sec) 29616.8867 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 8.7615
******************************93 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00093 | Step 00000 | Loss 0.5249 | Train Acc 0.8612 | Speed (samples/sec) 29624.5083 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7176
******************************94 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00094 | Step 00000 | Loss 0.5242 | Train Acc 0.8624 | Speed (samples/sec) 29600.3556 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.4837
******************************95 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00095 | Step 00000 | Loss 0.5209 | Train Acc 0.8628 | Speed (samples/sec) 29593.0402 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 7.1133
******************************96 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00096 | Step 00000 | Loss 0.5210 | Train Acc 0.8621 | Speed (samples/sec) 29530.3489 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 8.6019
******************************97 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00097 | Step 00000 | Loss 0.5234 | Train Acc 0.8622 | Speed (samples/sec) 29539.2522 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7503
******************************98 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00098 | Step 00000 | Loss 0.5178 | Train Acc 0.8629 | Speed (samples/sec) 29547.6828 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.7871
******************************99 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00099 | Step 00000 | Loss 0.5188 | Train Acc 0.8628 | Speed (samples/sec) 29556.1672 | GPU 3263.7 MB
[2021-06-10 06:49:14,593] [INFO] [logging.py:60:log_dist] [Rank 0] step=100, skipped=0, lr=[0.03], mom=[[0.8, 0.999]]
[2021-06-10 06:49:14,594] [INFO] [timer.py:160:stop] 0/100, SamplesPerSec=4055.9574170534306
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8377
******************************100 epoch 
 the length of training loader ------------------------------------------------------------
1
1
12

   ***************************     step   0   *************************************
-----------------------------------------step start------------------------
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------before blocks to device
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after blocks to device
 Nvidia-smi: 7.52978515625GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch train
 Nvidia-smi: 7.66455078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss
 Nvidia-smi: 7.25830078125GB

Max Memory Allocated 3.187253475189209  GigaBytes

-----------------------------------------after batch loss backward
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch 00100 | Step 00000 | Loss 0.5183 | Train Acc 0.8628 | Speed (samples/sec) 29562.0834 | GPU 3263.7 MB
-----------------------------------------after batch engine step
 Nvidia-smi: 7.40087890625GB

Max Memory Allocated 3.187253475189209  GigaBytes

Epoch Time(s): 6.8330
Eval Acc 0.8703
Test Acc: 0.6939
Avg epoch time(time.time()): 6983.902432024479 ms
